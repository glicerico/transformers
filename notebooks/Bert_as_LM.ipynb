{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate sentence probability with BERT\n",
    "## From https://github.com/huggingface/transformers/issues/37, but updated to newest transformers version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "\n",
    "# Load pre-trained model (weights)\n",
    "with torch.no_grad():\n",
    "    model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "    model.eval()\n",
    "    # Load pre-trained model tokenizer (vocabulary)\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS_TOKEN = '[CLS]'\n",
    "EOS_TOKEN = '[SEP]'\n",
    "MASK_TOKEN = '[MASK]'\n",
    "\n",
    "def score(sentence):\n",
    "    sm = torch.nn.Softmax(dim=0) # Softmax to convert logits to probs\n",
    "    \n",
    "    tokenized_input = tokenizer.tokenize(sentence)\n",
    "    if tokenized_input[0] != BOS_TOKEN:\n",
    "        tokenized_input.insert(0, BOS_TOKEN)\n",
    "    if tokenized_input[-1] != EOS_TOKEN:\n",
    "        tokenized_input.append(EOS_TOKEN)\n",
    "    ids_input = tokenizer.convert_tokens_to_ids(tokenized_input)\n",
    "    print(f\"Processing sentence: {tokenized_input}\")\n",
    "    print(f\"Sentence ids: {ids_input}\")\n",
    "#     tensor_input = torch.tensor([tokenizer.convert_tokens_to_ids(tokenized_input)])\n",
    "#     sentence_loss=0.\n",
    "    sent_prob = 1\n",
    "    \n",
    "    # Mask non-special tokens and calculates their probabilities\n",
    "    for i in range(1,len(tokenized_input)-1): # Ignore first and last tokens\n",
    "        current_tokenized = tokenized_input[:]\n",
    "        current_tokenized[i] = MASK_TOKEN\n",
    "        masked_input = torch.tensor([tokenizer.convert_tokens_to_ids(current_tokenized)])\n",
    "        outputs = model(masked_input)\n",
    "        predictions = outputs[0]\n",
    "        current_probs = sm(predictions[0, i]) # Softmax to get probabilities\n",
    "        current_prob = current_probs[ids_input[i]] # Prediction for masked word\n",
    "        sent_prob *= current_prob\n",
    "        \n",
    "        print(f\"Word: {tokenized_input[i]} \\t Prob: {current_prob}\")\n",
    "\n",
    "    return sent_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sentence: ['[CLS]', 'i', 'fed', 'my', 'cat', 'some', 'of', 'it', 'and', 'he', 'damn', 'near', 'passed', 'out', '[SEP]']\n",
      "Sentence ids: [101, 1045, 7349, 2026, 4937, 2070, 1997, 2009, 1998, 2002, 4365, 2379, 2979, 2041, 102]\n",
      "Word: i \t Prob: 0.9639779925346375\n",
      "Word: fed \t Prob: 0.13039857149124146\n",
      "Word: my \t Prob: 0.06296561658382416\n",
      "Word: cat \t Prob: 0.0026130476035177708\n",
      "Word: some \t Prob: 0.7925142645835876\n",
      "Word: of \t Prob: 0.9992772936820984\n",
      "Word: it \t Prob: 0.7004916667938232\n",
      "Word: and \t Prob: 0.8272475004196167\n",
      "Word: he \t Prob: 0.17570537328720093\n",
      "Word: damn \t Prob: 0.9917864203453064\n",
      "Word: near \t Prob: 0.9969384670257568\n",
      "Word: passed \t Prob: 0.550364077091217\n",
      "Word: out \t Prob: 6.173141997578568e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(5.6021e-14, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(\"I fed my cat some of it and he damn near passed out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:transformers]",
   "language": "python",
   "name": "conda-env-transformers-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
